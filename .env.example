# Ollama Configuration (for model-based policy)
# Only required if running with --model flag

# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# Model to use (any Ollama-supported model)
# Examples: qwen2.5:7b, llama2:7b, mistral:7b
OLLAMA_MODEL=qwen2.5:7b
